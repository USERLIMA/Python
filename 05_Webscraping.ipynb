{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40568fd4",
   "metadata": {},
   "source": [
    "## Webscraping\n",
    "\n",
    "Webscraping é uma técnica de extração de dados; com ela podemos coletar dados de sites. Fazemos a ‘raspagem’ dos dados que são interessantes para nós.\n",
    "\n",
    "Existem muitas empresas que utilizam como forma de gerar recursos, agragadores de links, comparadores de preços produtos são exemplo clássicos do usos de tecnicas e programas de webscraping.\n",
    "\n",
    "Ao se obter um conjunto de dados através de um webscraping podemos armzazená-los em arquivos com formatos distintos, a partir do próprio programa webscrping. Por exemplo:\n",
    "\n",
    "- salvar em um banco de dados;\n",
    "- salvar em CSV;\n",
    "- salvar em XLS;\n",
    "- salvar numa tabela dentro de um banco de dados NoSQL.\n",
    "\n",
    "### Primeiros passos para se construir uma aplicação Webscraping\n",
    "\n",
    "Para construirmos um programa webscraping são necessários alguns passos básicos:\n",
    "definir a natureza dos dados/informações que queremos pesquisar;\n",
    "pesquisar e definir os websites que receberão as pesquisas através do programa webscraping;\n",
    "fazer o mapeamento do código html dos sites escolhidos;\n",
    "criarmos o script e parametrizar os dados que serão recebidos.\n",
    "\n",
    "Possuir conhecimento prévio em tenologias relacionadas a websites(a menos html e css) é extremamente util para que seja possivel construir um pragama webscraping.\n",
    "\n",
    "#### WebScraping é realmente necessário?\n",
    "\n",
    "Quando queremos automatizar a busca de um volume de dados/informações siginificatvios dentro de websites ou plataformas de rede social, por exemplo, um programa webscraping torna-se fortemente necessário. Vamos partir da premissa que quermos buscar o preço de um mesmo produto em diferente plataformas de e-commerce: um webscrpaing pode fazer esse trabalho para nós a cada 2 minutos, por exemplo.\n",
    "\n",
    "Podemos, também, instruir nosso programa webscraping a buscar comentarios - dentro de redes sociais - sobre algum tema especifico. Com algumas linhas de código podemos automatizar esse processo. A unica coisa necessária - depois da implementação do código - é \"rodar\" nosso script\n",
    "\n",
    "### O que é necessário para criar um programa WebScraping\n",
    "\n",
    "Algumas ferramentas que já utilizamos para trabalahr com Python:\n",
    "distribuição Ancaconda ou a isntalação Python no sistema operacional do nosso computador;\n",
    "Jupyter Notebook ou uma IDE de sua prefencia;\n",
    "\n",
    "#### Construindo nosso programa WebScraping\n",
    "\n",
    "Vamos implementar o primeiro webscraping utilizando o método urlopen(). Para isso, precisamos - como primeira implementação - importar o módulo urllib.request para dentro de nosso programa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea212748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as libs\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Informando a url(endereco do site) que iremos extrair os dados\n",
    "url = 'http://pythonscraping.com/pages/page1.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dd7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementação da requisição necessária para capturar o código html\n",
    "codHTML = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c91fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codHTML.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ebbdbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-96ea6deea63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcodHTML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "codHTML = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b6445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
